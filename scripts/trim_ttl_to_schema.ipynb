{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25171571",
   "metadata": {},
   "source": [
    "shrink_ttl_to_schema_plus_samples.py\n",
    "\n",
    "Reduce a TTL file to \"schema + tiny instance samples\":\n",
    "- Keep ALL schema triples (RDFS/OWL axioms & declarations).\n",
    "- For instance data, keep up to:\n",
    "    * MAX_TRIPLES_PER_PREDICATE non-schema triples per predicate, and\n",
    "    * MAX_INSTANCES_PER_CLASS rdf:type assertions per class.\n",
    "- Optionally keep labels/comments for any subject that survives.\n",
    "\n",
    "Deterministic selection (stable sorting). Configure paths/limits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c771f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG — EDIT HERE ONLY\n",
    "# =========================\n",
    "file = \"big_one-test.ttl\"\n",
    "INPUT_TTL  = file\n",
    "OUTPUT_TTL = \"big_schema_for_prefix.ttl\"\n",
    "\n",
    "# Instance sampling limits\n",
    "MAX_TRIPLES_PER_PREDICATE = 1    # e.g., 1 or 2\n",
    "MAX_INSTANCES_PER_CLASS   = 1    # e.g., 1 or 2\n",
    "\n",
    "# Keep helpful annotations (labels/comments) for any resource in the final graph\n",
    "KEEP_LABELS_FOR_KEPT_RESOURCES   = True\n",
    "\n",
    "# Add SHACL schema constructs to the “always keep” list?\n",
    "INCLUDE_SHACL_SCHEMA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc46d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, BNode, Literal\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD, Namespace\n",
    "from typing import Tuple, Set, Dict, Iterable, DefaultDict\n",
    "from collections import defaultdict\n",
    "\n",
    "Triple = Tuple[object, object, object]\n",
    "\n",
    "# Namespaces (optional SHACL support)\n",
    "SH = Namespace(\"http://www.w3.org/ns/shacl#\")\n",
    "\n",
    "# --- schema recognizers ---\n",
    "SCHEMA_PREDICATES = {\n",
    "    # RDFS / RDF schema-level links\n",
    "    RDFS.domain, RDFS.range, RDFS.subClassOf, RDFS.subPropertyOf, RDFS.seeAlso,\n",
    "    # OWL schema axioms\n",
    "    OWL.equivalentClass, OWL.equivalentProperty, OWL.inverseOf, OWL.disjointWith,\n",
    "    OWL.propertyChainAxiom, OWL.onProperty, OWL.allValuesFrom, OWL.someValuesFrom,\n",
    "    OWL.hasValue, OWL.cardinality, OWL.minCardinality, OWL.maxCardinality,\n",
    "    OWL.qualifiedCardinality, OWL.minQualifiedCardinality, OWL.maxQualifiedCardinality,\n",
    "    OWL.unionOf, OWL.intersectionOf, OWL.complementOf, OWL.hasKey,\n",
    "}\n",
    "\n",
    "SCHEMA_TYPES = {\n",
    "    # RDFS / RDF\n",
    "    RDFS.Class, RDF.Property,\n",
    "    # OWL classes & properties\n",
    "    OWL.Class, OWL.Ontology, OWL.Restriction,\n",
    "    OWL.ObjectProperty, OWL.DatatypeProperty, OWL.AnnotationProperty,\n",
    "    OWL.FunctionalProperty, OWL.InverseFunctionalProperty,\n",
    "    OWL.SymmetricProperty, OWL.TransitiveProperty, OWL.ReflexiveProperty,\n",
    "    OWL.IrreflexiveProperty, OWL.AsymmetricProperty,\n",
    "}\n",
    "\n",
    "# SHACL schema bits (optional)\n",
    "if INCLUDE_SHACL_SCHEMA:\n",
    "    SCHEMA_PREDICATES |= {\n",
    "        SH.targetClass, SH.targetNode, SH.targetObjectsOf, SH.targetSubjectsOf,\n",
    "        SH.path, SH.property, SH.node, SH.datatype, SH.class_,\n",
    "        SH.minCount, SH.maxCount, SH.minInclusive, SH.maxInclusive, SH.minExclusive, SH.maxExclusive,\n",
    "        SH.pattern, SH.flags, SH.description, SH.name, SH.in_,\n",
    "        SH.and_, SH.or_, SH.xone, SH.not_, SH.hasValue, SH.qualifiedValueShape,\n",
    "        SH.qualifiedMinCount, SH.qualifiedMaxCount, SH.uniqueLang\n",
    "    }\n",
    "    SCHEMA_TYPES |= {\n",
    "        SH.Shape, SH.NodeShape, SH.PropertyShape, SH.ValidationReport, SH.ValidationResult\n",
    "    }\n",
    "\n",
    "def is_entity(n) -> bool:\n",
    "    return isinstance(n, (URIRef, BNode))\n",
    "\n",
    "def schema_triple(g: Graph, s, p, o) -> bool:\n",
    "    # 1) Any schema-signaling predicate\n",
    "    if p in SCHEMA_PREDICATES:\n",
    "        return True\n",
    "    # 2) Types that declare schema-y resources\n",
    "    if p == RDF.type and o in SCHEMA_TYPES:\n",
    "        return True\n",
    "    # 3) Ontology-level annotations (label/comment) if s is an OWL.Ontology\n",
    "    if p in (RDFS.label, RDFS.comment) and (s, RDF.type, OWL.Ontology) in g:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# --- deterministic scoring helpers for picking \"nice\" examples ---\n",
    "def score_instance_triple(t: Triple) -> Tuple:\n",
    "    \"\"\"Prefer entity-rich triples; then subject URIs over BNodes; then lexical.\"\"\"\n",
    "    s, p, o = t\n",
    "    entity_count = int(is_entity(s)) + int(is_entity(o))\n",
    "    subj_uri = int(isinstance(s, URIRef))\n",
    "    return (-entity_count, -subj_uri, str(s), str(p), str(o))\n",
    "\n",
    "def score_type_assertion(t: Triple) -> Tuple:\n",
    "    \"\"\"Prefer subjects that are URIs, then lexical.\"\"\"\n",
    "    s, p, o = t\n",
    "    subj_uri = int(isinstance(s, URIRef))\n",
    "    return (-subj_uri, str(s), str(o))\n",
    "\n",
    "def entities_in_triples(ts: Iterable[Triple]) -> Set[object]:\n",
    "    out = set()\n",
    "    for s, p, o in ts:\n",
    "        if is_entity(s): out.add(s)\n",
    "        if is_entity(o): out.add(o)\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    src = Graph()\n",
    "    src.parse(INPUT_TTL, format=\"turtle\")\n",
    "\n",
    "    picked: Set[Triple] = set()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) KEEP ALL SCHEMA TRIPLES\n",
    "    # -----------------------------\n",
    "    for s, p, o in src.triples((None, None, None)):\n",
    "        if schema_triple(src, s, p, o):\n",
    "            picked.add((s, p, o))\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 2) SAMPLE INSTANCE rdf:type assertions PER CLASS\n",
    "    # -----------------------------------------------------\n",
    "    # Collect all type assertions that are NOT declaring schema resources\n",
    "    by_class: DefaultDict[object, list] = defaultdict(list)\n",
    "    for s, p, o in src.triples((None, RDF.type, None)):\n",
    "        # If this type assertion declares a schema thing (o in SCHEMA_TYPES), it's already picked\n",
    "        if (s, p, o) in picked:\n",
    "            continue\n",
    "        if o in SCHEMA_TYPES:\n",
    "            # already covered by \"schema_triple\"; skip (to avoid double counting)\n",
    "            continue\n",
    "        by_class[o].append((s, p, o))\n",
    "\n",
    "    for cls, assertions in by_class.items():\n",
    "        assertions_sorted = sorted(assertions, key=score_type_assertion)\n",
    "        for t in assertions_sorted[:MAX_INSTANCES_PER_CLASS]:\n",
    "            picked.add(t)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 3) SAMPLE NON-SCHEMA TRIPLES PER PREDICATE\n",
    "    # -----------------------------------------------------\n",
    "    by_pred: DefaultDict[object, list] = defaultdict(list)\n",
    "    for s, p, o in src.triples((None, None, None)):\n",
    "        if (s, p, o) in picked:\n",
    "            continue\n",
    "        # Skip schema-signaling predicates entirely here; they’re already preserved.\n",
    "        if p in SCHEMA_PREDICATES:\n",
    "            continue\n",
    "        # # Also avoid re-adding type assertions already considered above\n",
    "        # if p == RDF.type:\n",
    "        #     continue\n",
    "        by_pred[p].append((s, p, o))\n",
    "\n",
    "    for pred, triples_ in by_pred.items():\n",
    "        triples_sorted = sorted(triples_, key=score_instance_triple)\n",
    "        for t in triples_sorted[:MAX_TRIPLES_PER_PREDICATE]:\n",
    "            picked.add(t)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 4) OPTIONAL: keep labels/comments for resources we kept\n",
    "    # -----------------------------------------------------\n",
    "    if KEEP_LABELS_FOR_KEPT_RESOURCES:\n",
    "        kept_entities = entities_in_triples(picked)\n",
    "        for ent in sorted(kept_entities, key=str):\n",
    "            for p in (RDFS.label, RDFS.comment):\n",
    "                for _, _, lit in src.triples((ent, p, None)):\n",
    "                    # ensure we only keep literal annotations\n",
    "                    if isinstance(lit, Literal):\n",
    "                        picked.add((ent, p, lit))\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 5) BUILD & WRITE OUTPUT\n",
    "    # -----------------------------------------------------\n",
    "    out = Graph()\n",
    "    # Useful prefix bindings\n",
    "    for prefix, namespace in src.namespace_manager.namespaces():\n",
    "        print(prefix, namespace)\n",
    "        out.bind(prefix, namespace)\n",
    "    out.bind(\"rdf\", RDF)\n",
    "    out.bind(\"rdfs\", RDFS)\n",
    "    out.bind(\"owl\", OWL)\n",
    "    out.bind(\"xsd\", XSD)\n",
    "    if INCLUDE_SHACL_SCHEMA:\n",
    "        out.bind(\"sh\", SH)\n",
    "\n",
    "    for t in sorted(picked, key=lambda x: (str(x[0]), str(x[1]), str(x[2]))):\n",
    "        out.add(t)\n",
    "\n",
    "    out.serialize(destination=OUTPUT_TTL, format=\"turtle\")\n",
    "\n",
    "    # Small console summary\n",
    "    print(\"=== Shrink complete ===\")\n",
    "    print(f\"Source triples:  {len(src)}\")\n",
    "    print(f\"Kept triples:    {len(out)}\")\n",
    "    print(f\"Output file:     {OUTPUT_TTL}\")\n",
    "    print(f\"- Schema preserved: YES\")\n",
    "    print(f\"- Instance limits:  {MAX_TRIPLES_PER_PREDICATE} per predicate, {MAX_INSTANCES_PER_CLASS} per class\")\n",
    "    if KEEP_LABELS_FOR_KEPT_RESOURCES:\n",
    "        print(\"- Labels/comments retained for kept resources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b880e4-69bb-41e4-8b99-b23e39190a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
